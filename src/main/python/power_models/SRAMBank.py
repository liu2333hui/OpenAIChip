#Based on the SRAM
#Two main states:
# Read and Write
# We assume are done sepeartely
# For same-cycle read/write, see other model: RF-file


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import LinearSVR, SVR
from sklearn.neural_network import MLPRegressor
import warnings
warnings.filterwarnings("ignore", category=FutureWarning, module="sklearn.utils.validation")
#script generated by AI deepseek
import pickle

if __name__ == "__main__":

	#create super set (read + write)
	

	# 加载数据
	# df = pd.read_csv("generated/SRAMBank/tsmc40_dataset.txt",  delimiter="\t")
	
	# 读取文件1和文件2
	df2 = pd.read_csv('generated/SRAMBanked/tsmc40_dataset_write.txt', delimiter='\t')

	df1 = pd.read_csv('generated/SRAMBanked/tsmc40_dataset_read.txt', delimiter='\t')
	# 为文件1添加 mode 列，值为 0
	df1['mode'] = 0 #read
	
	# 为文件2添加 mode 列，值为 1
	df2['mode'] = 1 #write
	
	df = pd.concat([df1,df2])#, ignore_index=True)
	# print(df)
	
	# 计算 toggle（假设 in_0 是字符串格式，例如 "0,3"）
	def calculate_toggle(in_0_str):
		# 分割字符串并转换为整数
		bits = list(map(int, in_0_str.split(',')))
		# 计算异或值（XOR）
		xor_result = bits[0] ^ bits[1]
		# print(bin(xor_result), bin(xor_result).count('1'))
		# 统计二进制中 1 的个数
		return bin(xor_result).count('1')

	def calculate_in(in_0_str):
		# 分割字符串并转换为整数
		bits = list(map(int, in_0_str.split(',')))
		# 计算异或值（XOR）
		return bits[1]
		# print(bin(xor_result), bin(xor_result).count('1'))
		# 统计二进制中 1 的个数
		# return bin(xor_result).count('1')
		
	# def calculate_mode_toggle(row):
		
	#     if row['mode'] == 0: #read
	#         return row['toggle'] * 2
	#     elif row['mode'] == 1: #write
	#         return row['toggle'] * 3
	#     else:
	#         return None  # 处理其他情况
	
	# df['new_column'] = df.apply(calculate_new_column, axis=1)	
		
		
	# 应用 toggle 计算
	df['toggle'] = df['write_data'].apply(calculate_toggle)
	print(df)
	# df['in'] = df['in_0'].apply(calculate_in)

	# 添加新列 1/CLOCK（注意避免除以 0）
	df['inv_CLOCK'] = 1 / df['CLOCK'].replace(0, np.nan)  # 如果 CLOCK 为 0，替换为 NaN
	# df = df.dropna()  # 删除包含 NaN 的行
	
	
	
	# 目标变量
	# print(df['in'])
	features = ['entry_bits', 'rows', 'inv_CLOCK', 'cap_load',] + ['mode', 'toggle']
	out = 'Total_Pwr'
	df = df
	
	# features = ['fanout', 'inv_CLOCK', 'cap_load']
	# out = 'coef'
	# df = final_df
	
	y = df[out]*1e10
	X = df[features]*1e5
	X = np.log1p(X)
	y = np.log1p(y)	
		
	
	X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
	
	# X_train = X
	# X_test = X
	# y_train = y
	# y_test = y
	
	# 6. 定义模型列表
	models = {
	    "LinearRegression": LinearRegression(),
	    "DecisionTreeRegressor": DecisionTreeRegressor(random_state=42),
	    "RandomForestRegressor": RandomForestRegressor(random_state=42),
	    "GradientBoostingRegressor": GradientBoostingRegressor(random_state=42),
	    "LinearSVR": LinearSVR(random_state=42),
	    "SVR": SVR(),
	    "MLPRegressor": MLPRegressor(random_state=42, max_iter=1000)
	}
	
	# 4. 遍历模型，训练并评估
	results = {}
	
	trained_models = {}
	def log1p_inverse(x):
	    return np.exp(x) - 1
			
	for name, model in models.items():
	    # 训练模型
	    model.fit(X_train, y_train)
	    
	    # 预测
	    # print(X_test)
	    # exit(0)
	    y_pred = model.predict(X_test)
	    
	    # 计算评估指标
	    mae = mean_absolute_error(y_test, y_pred)
	    mse = mean_squared_error(y_test, y_pred)
	    rmse = np.sqrt(mse)
	    
	    # 计算相对误差

			
	    relative_error = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
		
	    rel_err_inverse = np.mean(np.abs((log1p_inverse(y_test) - log1p_inverse(y_pred)) / log1p_inverse(y_test))) * 100
	    print(log1p_inverse(y_test)/1e10)
		# print("data")
	    # print(log1p_inverse(y_test))
	    # print(log1p_inverse(y_pred))
	    # 保存结果
	    results[name] = {
	        "MAE": mae,
	        "MSE": mse,
	        "RMSE": rmse,
	        "Relative Error (%)": relative_error,
			"rel_err_inverse":rel_err_inverse
	    }
	    trained_models[name] = model
	    # 打印结果
	    print(f"Model: {name}")
	    print(f"  MAE: {mae}")
	    print(f"  MSE: {mse}")
	    print(f"  RMSE: {rmse}")
	    print(f"  Relative Error (%): {relative_error}")
	    print(f"  rel_err_inverse (%): {rel_err_inverse}")
	    print("-" * 30)
	
	# 5. 找到表现最好的模型
	best_model = min(results, key=lambda x: results[x]['RMSE'])
	print(f"\nBest Model: {best_model}")
	print(f"  RMSE: {results[best_model]['RMSE']}")
	print(f"  Relative Error (%): {results[best_model]['Relative Error (%)']}")
	print(f"  rel_err_inverse (%): {results[best_model]['rel_err_inverse']}")
	
	with open('generated/PowerModels/SRAMBank.pkl', 'wb') as f:
	    pickle.dump(trained_models[best_model], f)
	
	
	# # toggle vs. power
	data = [[16, 256, 1, 0.1, 1, 5]
		]
	testing_df = pd.DataFrame(data, columns=features)
	X = np.log1p(testing_df[features]*1e5)
	
	best_m = trained_models[best_model]
	y =  log1p_inverse(best_m.predict(X))/1e10
	print(y)
	# import matplotlib.pyplot as plt
	# plt.plot([1,1.5,2,5.5,7.5, 8], y )
	# plt.show()
	
	
