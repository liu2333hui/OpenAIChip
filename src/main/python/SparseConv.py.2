from ArchTemplates import GeneralConvUnit, GeneralLinearUnit, generate_cpp, dict_to_str, filter_loop_order

import numpy as np
import paddle.nn as nn
import paddle
import pandas as pd

from power_models.AccumulatorPrimitive import AccumulatorPrimitive
from power_models.AdderNPrimitive import AdderNPrimitive
from power_models.Multiplier2Primitive import Multiplier2Primitive
from power_models.ConstantMultiplierPrimitive import ConstantMultiplierPrimitive

class SparseConv(GeneralConvUnit):
	def get_primitive_statistics(self):				
		if(self.hc["MULT_SIDE"] == "weight"):
			MULTIPLIER_bins = ['weights_data', 'inputs_data']		
			MULT_prec1 = self.hc['WEI_PREC']
			MULT_prec2 = self.hc["ACT_PREC"]	
		else:
			MULTIPLIER_bins = ['weights_data', 'inputs_data'][::-1]
			MULT_prec1 = self.hc['ACT_PREC']
			MULT_prec2 = self.hc["WEI_PREC"]	
		

		SPARSE_RATIO = self.hc["SPARSE_RATIO"]
		SPARSE_SIDE = self.hc["SPARSE_SIDE"]
		WEI_ZERO_MAP_EN = self.hc["ZERO_MAP_EN"]		
		ACT_ZERO_MAP_EN = self.hc["ZERO_MAP_EN"]		


		#MODULES characterizes a NET in the netlist, can be a component
		#or can be just a NET
		self.MODULES =  {
			#Select NonZero Weights
			"WEI_CROSSBAR": {		
				"units": self.hc["TN"]*self.hc["TB"]*self.hc["TY"]*self.hc["TX"],
				"input_metadata": {
				"toggle": {
					"update2": f'''0//__builtin_popcount(cur_wei_crossbar[wei_crossbar][jjj]^prev_wei_crossbar[wei_crossbar][jjj]) ''',
					"update": '0',			}
	
			},
				"input_bins": [ self.hc["WEI_PREC"]*self.hc["TI"]*self.hc["TKY"]*self.hc["TKY"] ,  (self.hc["TI"]*self.hc["TKY"]*self.hc['TKX'])//SPARSE_RATIO  ],	
				"input_group": self.hc["TI"]*self.hc["TKX"]*self.hc['TKY'],
#, 
#				self.hc["TI"]*self.hc["TKX"]*self.hc["TKY"]], #for accumulation

				#trading physical for time, used for sparse flow at the crossbar
				"input_hold_cycles":[2, 2] ,#["max_valid_updated_store_wei_crossbar[0][s]" , "max_valid_updated_store_wei_crossbar[1][s]" ],#[SPARSE_RATIO, SPARSE_RATIO],#"max_valid_updated_store_wei_crossbar[jjj][s]

				"input_time_unrolled": [1, SPARSE_RATIO ],
				"input_trace_name": [ "in", "sel"],
				#"inner_loop_unroll": SPARSE_RATIO,	
				#"input_hold_cycles": [SPARSE_RATIO , 1], #"valid_inner_terms"

				"accumulated_input": False,

					
				"update_condition": ['1', 'weights_data != 0'],
				"cur_update": [  'weights_data', 'weights_data'  ],
				'prev_update': [ 'weights_data', 'weights_data'  ],#['weights_data', 'inputs_data'],

				"output_metadata": {},

				"output_bins":  self.hc["WEI_PREC"] ,
				"output_update": 'weights_data',
				"output_condition": 'weights_data != 0',	
				"output_inner_group": self.hc["TI"]*self.hc["TKX"]*self.hc["TKY"]//SPARSE_RATIO,
				#"output_outer_group": self.hc["TN"]*self.hc["TB"]*self.hc["TX"]*self.hc["TY"],

			
				'reset_trigger': [],

				#meaning output is accumulated
				'accumulate': False,#meaning the output is accumulated
				'accumulate_op': '',
	
				"config": {
					"primitive": "networks.Crossbar",
					"type": self.hc["WEI_CROSSBAR_TYPE"],
					"prec": self.hc["WEI_PREC"],
					"out_prec": self.hc["WEI_PREC"]*2,
					"terms": 1,
				},
				'hooks': {

				"core_before_outer_group_start": "",
				"core_before_inner_group_start": "",
				"core_after_inner_group_start":"",
				"core_after_data_fetch":"",
				"core_after_inner_group_end":"",
				"core_after_outer_group_end": ""

				},


			},
		"ADDER_TREE": {
			"units": self.hc["TN"]*self.hc["TB"]*self.hc["TX"]*self.hc["TY"],
			"input_metadata": {},
			"input_bins": [self.hc["ADDER_TREE_PREC"]],

				'cur_update': MULTIPLIER_bins,#[ 'weights_data', 'inputs_data'],
				'input_group': 1,
				"output_metadata": { },
				"output_bins": self.hc["WEI_PREC"]+self.hc["ACT_PREC"],
				"output_update": 'weights_data * inputs_data',
				"output_condition": '',
				#"output_inner_group": ""


				"accumulated_input": False,

	
			
		},
		"PE_ARRAY": {
				"units": (self.hc["TI"]*self.hc["TN"]*self.hc["TB"]*self.hc["TKX"]*self.hc["TKY"]*self.hc["TX"]*self.hc["TY"] ),# //SPARSE_RATIO,
				"input_metadata": {"bits": {
					"update": f"__builtin_popcount(weights_data) + {self.hc['WEI_PREC']}*__builtin_popcount(inputs_data)"
				}},
				"input_bins": [self.hc["WEI_PREC"], self.hc["ACT_PREC"]],
				"inner_loop_unroll": SPARSE_RATIO,	
				'update_condition': 'weights_data != 0',#[ "weights_data != 0", "weights_data !=  0"  ],
				'cur_update': MULTIPLIER_bins,#[ 'weights_data', 'inputs_data'],
				#'prev_update': MULTIPLIER_bins,#['weights_data', 'inputs_data'],
				'input_group': 1,
				"output_metadata": { },
				"output_bins": self.hc["WEI_PREC"]+self.hc["ACT_PREC"],
				"output_update": 'weights_data * inputs_data',
				"output_condition": '',
				#"output_inner_group": ""


				"accumulated_input": False,

				'reset_trigger': [],
				'accumulate': False,
				'accumulate_op': '',
				"config": {
					"primitive": "multipliers.Multiplier2",
					"multiplierType": self.hc["MULT_TYPE"],
					"adderType": self.hc["MULT_CORE_ADDER_TYPE"],
					"side": self.hc.get("MULT_SIDE", "weight"),
					"prec1":MULT_prec1, "prec2": MULT_prec2, "radix": self.hc['MULT_RADIX']
				}
			},


			"L1_OUT": {
				"units": self.hc["TN"]*self.hc["TN"],
				"config": {

				}	
			},
			"L1_WEI": {
				"units": self.hc["TI"]*self.hc["TN"],
				"config": {

				}
			},
			"L1_ACT": {
				"units": self.hc["TI"]*self.hc["TB"],
				"config": {

				}
			},
			"L2_WEI": {
				"units": 512,
				"config": {

				}
			},
		}
		
	def infer_crossbar(self, params):
		PARAMETERS = params['params']
		DATA = [
			params['inputs_obj'],
			params['weights_obj']]
		NET_DATA = {
			"WEI_CROSSBAR": self.MODULES["WEI_CROSSBAR"]
		}	
		LOOP_ORDER = self.hc["LOOP_ORDER"]
		LOOP_VAR_DEFINITIONS = self.LOOP_VAR_DEFINITIONS			
		hooks = {}#self.MODULES["PE_ARRAY"]["hooks"]
		name = params["SIM_PARAMS"]["name"]
		root = params["SIM_PARAMS"]["root"]
		output_files= generate_cpp(root, name, PARAMETERS, DATA, NET_DATA, LOOP_ORDER, LOOP_VAR_DEFINITIONS,tiling_pre="T",hardware_config= self.hc, SIM_CYCLE_LIM = params['SIM_PARAMS']['SIM_CYCLES'], hooks = hooks, run_it = params['SIM_PARAMS']["RUN_CPP"], need_trace = params['SIM_PARAMS']['GEN_TRACE'] )
		return output_files
	
	
	def infer_pe(self,params):
		#any parameters we want to copy into the cpp
		PARAMETERS = params['params']
		#data we want to copy to the cpp
		DATA = [
			params['inputs_obj'],
			params['weights_obj']]
		#nets / hardware modules we want to track the toggling and features of 
		NET_DATA = {
			"PE_ARRAY": self.MODULES["PE_ARRAY"]
		}	
		#loop orders and such
		LOOP_ORDER = self.hc["LOOP_ORDER"]
		#variable definitions
		LOOP_VAR_DEFINITIONS = self.LOOP_VAR_DEFINITIONS			
		



		hooks = {}#self.MODULES["PE_ARRAY"]["hooks"]
		#generate the c++ file
		name = params["SIM_PARAMS"]["name"]
		root = params["SIM_PARAMS"]["root"]

		output_files= generate_cpp(root, name, PARAMETERS, DATA, NET_DATA, LOOP_ORDER, LOOP_VAR_DEFINITIONS,tiling_pre="T",hardware_config= self.hc, SIM_CYCLE_LIM = params['SIM_PARAMS']['SIM_CYCLES'], hooks = hooks, run_it = params['SIM_PARAMS']["RUN_CPP"], need_trace = params['SIM_PARAMS']['GEN_TRACE'] )

		return output_files
	
	def infer_adder_accum(self,params):
		return {}	

	def infer_buffers(self,params): 
		return {}	


	def prepare_data(self, params):
		#convolution data

		input_data = params['input_data']
		weights = params['weight']

		#convolution prepare
		#input_data = input_data[0] #if is tuple
		OUT =  weights.shape[0]
		IN = weights.shape[1]
		KX = weights.shape[2]
		KY = weights.shape[3]

		BAT = input_data.shape[0]
		input_IN = input_data.shape[1]
		X = input_data.shape[2]
		Y = input_data.shape[3]
		print(input_data.shape)
		print(weights.shape)
		assert(input_data.shape[1] == weights.shape[1])
		
		#quantize (fixed point)
		#(todos) some algorithm to choose the scaling ?
		weights    = ((weights*256*256) %self.hc['WEI_PREC']).astype(np.int32)
		input_data = ((input_data*256*256) %self.hc['ACT_PREC']).astype(np.int32)
		#Randomize weights and inputs (TODOS)
		Randomize = params["SIM_PARAMS"]["Randomize"]
		Wei_Sparsity = params["SIM_PARAMS"]["Wei_Sparsity"]
		Act_Sparsity = params["SIM_PARAMS"]["Act_Sparsity"]
		name = params["SIM_PARAMS"]["name"]
		root = params["SIM_PARAMS"]["root"]

		np_save= params['SIM_PARAMS']['save_np']
	

		#Randomize weights and inputs (TODOS)
		if(Randomize):
			n = IN*OUT*KX*KY
	
			k = int(n*Wei_Sparsity)
			rand_wei = np.random.randint(0, 1<<self.hc["WEI_PREC"], size=n)
			zero_indices = np.random.choice(n, k, replace=False)
			rand_wei[zero_indices] = 0
			
			n = IN*BAT*X*Y
	
			k = int(n*Act_Sparsity)
			rand_act = np.random.randint(0, 1<<self.hc["ACT_PREC"], size=n)
			zero_indices = np.random.choice(n, k, replace=False)
			rand_act[zero_indices] = 0
			
			weights = rand_wei.reshape((OUT, IN, KX, KY))
			input_data = rand_act.reshape((BAT, IN, X, Y))
		
		w_file = root+"/"+name+".weights.txt"
		i_file = root+"/"+name+".input.txt"
		if(np_save):
			weights = rand_wei.reshape((-1))#OUT, IN, KX, KY))
			input_data = rand_act.reshape((-1))#BAT, IN, X, Y))
	
			np.savetxt(w_file, weights, fmt='%d', delimiter='\n')
			np.savetxt(i_file, input_data, fmt='%d', delimiter='\n')
			weights = rand_wei.reshape((-1))#OUT, IN, KX, KY))
			input_data = rand_act.reshape((-1))#BAT, IN, X, Y))
	
			weights = rand_wei.reshape((OUT, IN, KX, KY))
			input_data = rand_act.reshape((BAT, IN, X, Y))
	
		return {
			"params":{
				"IN": IN,
				"OUT": OUT,
				"BAT": BAT,	
				"FILTER_KX": KX, 
				"FILTER_KY": KY,
				"INPUT_X": X,
				"INPUT_Y": Y,

			},
			"weights_obj": 
				{
				"name": "weights",
				"file": w_file,
				"size": len(weights.reshape((-1))),
				"indexing": "n*IN*FILTER_KX*FILTER_KY+i*FILTER_KX*FILTER_KY+ky*FILTER_KX+kx"
			},
			"inputs_obj":
				{
				"name": "inputs",
				"file": i_file,
				"size": len(input_data.reshape((-1))),
				"indexing": "b*IN*INPUT_X*INPUT_Y+i*INPUT_X*INPUT_Y + y*INPUT_X + x"	
			},
		}
		
	def infer(self, params):
		self.get_primitive_statistics()
		self.LOOP_VAR_DEFINITIONS = {
			"B": {
				"LIM": "BAT",
				"STRIDE": 1,
				"GROUP": "OUTER"
			},
			"I": {
				"LIM": "IN",
				"STRIDE": 1,
				"GROUP": "INNER", #meaning can be collected together in the sum
			},
			"N": {
				"LIM": "OUT",
				"STRIDE": 1,
				"GROUP": "OUTER"
			},	
			"X": {
				"LIM": "INPUT_X",
				"STRIDE": params['stride'][0],	
				"GROUP": "OUTER",
			},
			"Y": {
				"LIM": "INPUT_Y",
				"STRIDE": params['stride'][1],	
				"GROUP": "OUTER",
			},
			"KX": {
				"LIM": "FILTER_KX",
				"STRIDE": 1,#params['stride'],	
				"GROUP": "INNER",
			},
			"KY": {
				"LIM": "FILTER_KY",
				"STRIDE": 1,#params['stride'],	
				"GROUP": "INNER",
			},


	
		}


		print(params)	
		p = params
		p.update(self.prepare_data(p))

		results = []

		#results.append(self.infer_pe(p))
		results.append(self.infer_crossbar(p))


		#if(p.get("RUN_PE",1)):
		#	results.append(self.infer_pe(p))
		#if(p.get("RUN_ADDER_ACCUM", 1)):
		#	results.append(self.infer_adder_accum(p))
		#if(p.get("RUN_BUFFERS",1)):
		#	results.append(self.infer_buffers(p))
		return results


if __name__ == "__main__":
		

	hardware_config = {
	"WEI_PREC": 8,
	"ACT_PREC": 8,

	"TB": 1,
	"TN": 1,
	"TI": 4,
	"TX": 1,
	"TY": 1,
	"TKX": 1,
	"TKY": 1,
	"LOOP_ORDER": ["B", "N", "I", "X", "Y", "KX", "KY"],

	"SPARSE_RATIO": 4, #we can compress from 4 to 4
	"SPARSE_SIDE": "weight",
	"ZERO_MAP_EN": 1,


	"WEI_CROSSBAR_TYPE": "Full",#Full, Partial, Butterfly, Benes, 
	"ACT_CROSSBAR_TYPE": "Full",

	"MULT_TYPE": "HighRadixMultiplier",
	"MULT_SIDE": "weight",
	"MULT_RADIX": 4,
	"MULT_CORE_ADDER_TYPE": "SimpleAdder2",

	"ADDER_TREE_TYPE": "Simple",
	"ADDER_TREE_PREC": 16,

	"ACCUM_TYPE": "BitSerial",
	"ACCUM_PREC": 32,

	"SRAM_SIZE": [8, 64],
	"SRAM_TYPE": "Reg",
	"L1_WEI_LEN" : 512,
	"L1_ACT_LEN" : 64,
	"L2_LEN" : 512,
	"DRAM_LEN": 512,

	"CLOCK": 1,
	"cap_load": 0.1,
	"tech":"tsmc40",

	}

	input_data = paddle.randn([4, 32, 28, 28])
	layer = nn.Conv2D(in_channels=32, out_channels=64, kernel_size=3)#skip bias for now
	output_data = layer(input_data) 	
	repr_str = repr(layer)
	weight_name = repr(layer).replace("(", "_").replace(")", "_").replace(",", "_").replace("=", "_").replace(" ", "_").replace("]","_").replace("[","_")
	input_name = repr(input_data.shape).replace("(", "_").replace(")", "_").replace(",", "_").replace("=", "_").replace(" ", "_").replace("]","_").replace("[","_")

	print(weight_name)
	print(input_name)
	#exit()
	network = {
	"input_data" :input_name,
		"layer": weight_name,
	
	}
	
	print(layer)
	network_layer = {
	"layer_name": dict_to_str(network),#"Conv1",
	"layer": layer,
	"input_data": input_data,
	"output_data": output_data,
	}
	mapping = {
	"Linear1": "df1",
	}

	design = dict_to_str(hardware_config)

	SIM_PARAMS = {
	"name": network_layer['layer_name'],
	"root": f"generated/Architecture/SparseConv/{design}",
	"SIM_CYCLES": 10,
	"Randomize": 1,
	"Wei_Sparsity": 0.5,
	"Act_Sparsity": 0.1,	
	'save_np':True,#False,# True,

	#0: Baseline compare against golden
	#generate trace and cpp 
	#use specified sim-cycles

	#1: inference time
	#no trace, run_cpp, simcycles is -1

	#2: Debug-mode
	#Assume trace generated
	#only fine-tune the model powers
	'MODE': 4,
	"RUN_GOLDEN_SBT": 1,
	
	#'GEN_TRACE':True,
	'RUN_CPP': True
}
	SIM_PARAMS['name'] = SIM_PARAMS['name']+"_"+str(SIM_PARAMS["Wei_Sparsity"])+"_"+str(SIM_PARAMS['Act_Sparsity'])

	if(SIM_PARAMS['MODE'] == 0):
		SIM_PARAMS['GEN_TRACE'] = True
		SIM_PARAMS['RUN_CPP'] = True
		SIM_PARAMS['save_np'] = True	
	elif(SIM_PARAMS['MODE'] == 1):
		SIM_PARAMS['GEN_TRACE'] = False
		SIM_PARAMS['RUN_CPP'] = True
		SIM_PARAMS['save_np'] = True	
	elif(SIM_PARAMS['MODE'] == 2):	
		SIM_PARAMS['GEN_TRACE'] = False
		SIM_PARAMS['RUN_CPP'] = False
		SIM_PARAMS['save_np'] = False
	elif(SIM_PARAMS['MODE'] == 3):	
		SIM_PARAMS['GEN_TRACE'] = True
		SIM_PARAMS['RUN_CPP'] = False
		SIM_PARAMS['save_np'] = True
	elif(SIM_PARAMS['MODE'] == 4):	
		SIM_PARAMS['GEN_TRACE'] = True
		SIM_PARAMS['RUN_CPP'] = False
		SIM_PARAMS['save_np'] = False
	

	#FLOW 1. compare against baselines and 
	ld =  SparseConv(hardware_config)
	traces = ld.gen_perf_trace(network_layer,mapping, SIM_PARAMS) 
	exit()
	ld.estimate_golden_pwr(traces, network_layer,mapping, SIM_PARAMS)
	ld.estimate_our_pwr_v1(traces,network_layer,mapping, SIM_PARAMS)	
	ld.estimate_our_pwr(traces,network_layer,mapping, SIM_PARAMS)
	ld.estimate_b1_pwr(traces,network_layer, mapping,SIM_PARAMS)#maestro
	ld.estimate_b2_pwr(traces, network_layer,mapping,SIM_PARAMS)#accelergy 
	ld.estimate_b3_pwr(traces, network_layer,mapping,SIM_PARAMS)#others?


